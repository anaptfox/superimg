# Introducing SuperImg

This is a video. It's also a TypeScript function.

```ts
import { defineTemplate } from 'superimg'

export default defineTemplate({
  render(ctx) {
    const { width, height, sceneProgress } = ctx

    const opacity = Math.min(1, sceneProgress * 3)
    const scale = 0.8 + sceneProgress * 0.2

    return `
      <div style="
        width: ${width}px;
        height: ${height}px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        display: flex;
        align-items: center;
        justify-content: center;
      ">
        <h1 style="
          font-family: system-ui, sans-serif;
          font-size: 80px;
          font-weight: bold;
          color: white;
          opacity: ${opacity};
          transform: scale(${scale});
        ">Hello, World!</h1>
      </div>
    `
  },
})
```

<PlayerDemo templateId="hello-world" />

`render` gets called once per frame. `sceneProgress` goes from `0` to `1` over the clip's duration. The return value is an HTML string. That string gets rasterized into a pixel frame, and the frames get encoded into an MP4.

That's the whole model. A video is a pure function of time. Same input, same output—deterministic, testable, composable, like any other TypeScript module.

---

## Adding easing

The example above uses `Math.min` for a linear fade-in. Real motion needs easing curves. SuperImg provides `std.tween()` to compose easing + interpolation in one call, plus math helpers for clamping and mapping:

```ts
render(ctx) {
  const { std, sceneTimeSeconds: time } = ctx

  // Map the first second of time to a 0–1 progress value
  const progress = std.math.clamp(time / 1.0, 0, 1)

  const opacity = std.tween(0, 1, progress, 'easeOutCubic')
  const y = std.tween(30, 0, progress, 'easeOutCubic')

  return `
    <h1 style="
      opacity: ${opacity};
      transform: translateY(${y}px);
    ">...</h1>
  `
}
```

Two functions turn a mechanical linear fade into smooth deceleration: `clamp` bounds time to a 0–1 range, and `tween` maps it to the value you need with your chosen easing curve. Swap in `easeOutBounce` or `easeOutElastic` and the character of motion changes completely.

---

## Making it data-driven

Hardcoded text is a demo. Real templates need data. Add a `defaults` object and the values become overridable at render time:

```ts
import { defineTemplate } from 'superimg'

export default defineTemplate({
  defaults: {
    title: 'Welcome',
    subtitle: 'Customize via data',
    accentColor: '#667eea',
  },
  render(ctx) {
    const { data, std, sceneTimeSeconds: time, width, height } = ctx
    const { title, subtitle, accentColor } = data

    const progress = std.math.clamp(time / 1.0, 0, 1)
    const opacity = std.tween(0, 1, progress, 'easeOutCubic')
    const y = std.tween(30, 0, progress, 'easeOutCubic')

    return `
      <div style="
        width: ${width}px;
        height: ${height}px;
        background: linear-gradient(135deg, #0f0f23, #1a1a2e);
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        font-family: system-ui, sans-serif;
      ">
        <h1 style="
          font-size: 64px;
          color: ${accentColor};
          opacity: ${opacity};
          transform: translateY(${y}px);
          margin: 0;
        ">${title}</h1>
        <p style="
          font-size: 24px;
          color: white;
          opacity: ${opacity * 0.8};
          transform: translateY(${y}px);
          margin-top: 16px;
        ">${subtitle}</p>
      </div>
    `
  },
})
```

<PlayerDemo templateId="complete-template" duration={4} />

`defaults` provides the fallback values. At render time, pass overrides—a different title, a different color—and the template produces a different video from the same code.

---

## Rendering

One command to go from template to MP4:

```bash
npx superimg render template.ts -o video.mp4
```

The pipeline: TypeScript compiles to a `render` function, each frame calls it to produce HTML, a headless browser rasterizes the HTML to pixels, and ffmpeg encodes the pixel frames into a video file. Templates also run in the browser with live preview at 60fps, and SuperImg ships a `<Player>` React component for embedding in apps.

---

## Why a function, not a component tree

Other tools for programmatic video give you a component tree and a timeline. SuperImg gives you a function. No component lifecycle, no virtual DOM, no reconciler—just a string of HTML per frame, rasterized and encoded.

This makes templates portable. They're plain TypeScript modules that return strings. You can unit test them with `assert.equal`. You can generate them from other code. You can run them anywhere JavaScript runs—browser, CLI, CI, serverless. The mental model is `(time) → HTML → pixels`, and nothing else.

The trade-off is intentional: you give up declarative composition for total control over every pixel in every frame.

---

## What's next

The core pipeline—define, preview, render—works today. What's coming:

- **Asset system**: fonts, images, and audio declared in template config
- **Server-side rendering**: the same template, rendered via Node API for cloud workflows

---

## Try it

Open the [editor](/) and start building. Or render locally:

```bash
npx superimg render template.ts -o video.mp4
```

Every frame is just HTML.
